#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import math
import time
import logging
import traceback
from datetime import datetime, date
from zoneinfo import ZoneInfo
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import requests
from dotenv import load_dotenv

# ====== å°ˆæ¡ˆå…§æ¨¡çµ„ï¼ˆæ²¿ç”¨ä½ ç¾æœ‰çš„å–æ•¸é‚è¼¯ï¼‰ ======
# - TWSE/TPEX åå–®ï¼šè«‹ç¢ºä¿ fetch_twse_listed_equities() å›å‚³æ¬„ä½è‡³å°‘åŒ…å« code/name/exchange
#   ä¸¦å·²åŒæ™‚ç´å…¥ ä¸Šå¸‚(TWSE) + ä¸Šæ«ƒ(TPEX) æ™®é€šè‚¡
from universe.twse_listed import fetch_twse_listed_equities
# - Yahoo æ­·å²åƒ¹é‡
from data_sources.yahoo import download_ohlcv_batches
# - Yahoo å¸‚å€¼ï¼ˆå›å‚³æ–°å°å¹£ï¼‰
from data_sources.yahoo_meta import get_market_caps


# ====== ç›®éŒ„èˆ‡è¨˜éŒ„æª” ======
ROOT = Path(__file__).resolve().parents[1]
OUTPUT_DIR = ROOT / "output"
LOG_DIR = ROOT / "logs"
STATE_DIR = ROOT / "state"                   # ç”¨ä¾†å­˜é€£çºŒå‡ºç¾çš„ streaks
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)
STATE_DIR.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.FileHandler(LOG_DIR / "app.log", encoding="utf-8"),
              logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("twse_tpex_kd_screener")


# ====== è®€å– .env ======
def _to_bool(s: Optional[str], default: bool) -> bool:
    if s is None:
        return default
    return s.strip().lower() in ("1", "true", "yes", "y", "on")

def get_env_params() -> Dict:
    load_dotenv(ROOT / ".env", override=True)

    params = dict(
        # --- ç”¢å‡ºæ•¸é‡ ---
        TOP_N=int(os.getenv("TOP_N", "20")),

        # --- KD ---
        KD_N=int(os.getenv("KD_N", "9")),
        KD_K_SMOOTH=int(os.getenv("KD_K_SMOOTH", "3")),
        KD_D_PERIOD=int(os.getenv("KD_D_PERIOD", "3")),
        KD_CROSS_WINDOW=int(os.getenv("KD_CROSS_WINDOW", "3")),

        # --- åƒ¹é‡ ---
        VOLUME_LOOKBACK=int(os.getenv("VOLUME_LOOKBACK", "20")),
        VOLUME_MULTIPLIER=float(os.getenv("VOLUME_MULTIPLIER", "1.5")),

        # --- è¶¨å‹¢è¦å‰‡ï¼ˆé–‹é—œ + åƒæ•¸ï¼‰ ---
        ENABLE_RULE_MA5_GT_MA20=_to_bool(os.getenv("ENABLE_RULE_MA5_GT_MA20", "true"), True),
        ENABLE_RULE_OC_ABOVE_MA20=_to_bool(os.getenv("ENABLE_RULE_OC_ABOVE_MA20", "true"), True),
        ENABLE_RULE_LAST5_MA10_THRESHOLD=_to_bool(os.getenv("ENABLE_RULE_LAST5_MA10_THRESHOLD", "true"), True),
        MAX_DAYS_BELOW_MA10_IN_5=int(os.getenv("MAX_DAYS_BELOW_MA10_IN_5", "3")),

        # --- é»‘K é™åˆ¶ ---
        ENABLE_RULE_BLACK_CANDLE_LIMIT=_to_bool(os.getenv("ENABLE_RULE_BLACK_CANDLE_LIMIT", "true"), True),
        BLACK_CANDLE_MAX_DROP=float(os.getenv("BLACK_CANDLE_MAX_DROP", "0.95")),  # Close >= Open * 0.95

        # --- æµé€šæ€§ ---
        LIQ_MIN_DAYS=int(os.getenv("LIQ_MIN_DAYS", "10")),
        LIQ_MIN_SHARES=int(os.getenv("LIQ_MIN_SHARES", "1000000")),

        # --- å¸‚å€¼ï¼ˆTWDï¼‰ ---
        MARKET_CAP_MIN=float(os.getenv("MARKET_CAP_MIN", "10000000000")),

        # --- Yahoo æŠ“å– ---
        BATCH_SIZE=int(os.getenv("BATCH_SIZE", "120")),

        # --- Telegram ---
        TELEGRAM_BOT_TOKEN=os.getenv("TELEGRAM_BOT_TOKEN"),
        TELEGRAM_CHAT_ID=os.getenv("TELEGRAM_CHAT_ID"),

        # --- é€£çºŒå‡ºç¾ key ---
        CONTINUATION_KEY=os.getenv("CONTINUATION_KEY", "yahoo"),
    )
    logger.info(
        "Params loaded: KD=(%d,%d,%d), window=%d, VOL: N=%d x%.2f, "
        "MA rules: 5>20=%s, OC>=MA20=%s, 5d<MA10<=%d=%s, BlackK<=5%%=%s, "
        "LIQ: days=%d >= %d, TOP_N=%d, MCAP_MIN=%.0f",
        params["KD_N"], params["KD_K_SMOOTH"], params["KD_D_PERIOD"], params["KD_CROSS_WINDOW"],
        params["VOLUME_LOOKBACK"], params["VOLUME_MULTIPLIER"],
        params["ENABLE_RULE_MA5_GT_MA20"], params["ENABLE_RULE_OC_ABOVE_MA20"],
        params["MAX_DAYS_BELOW_MA10_IN_5"], params["ENABLE_RULE_LAST5_MA10_THRESHOLD"],
        params["ENABLE_RULE_BLACK_CANDLE_LIMIT"],
        params["LIQ_MIN_DAYS"], params["LIQ_MIN_SHARES"],
        params["TOP_N"], params["MARKET_CAP_MIN"]
    )
    return params


# ====== å·¥å…·ï¼šSMA / KD / äº¤å‰åµæ¸¬ ======
def sma(series: pd.Series, n: int) -> pd.Series:
    return series.rolling(n, min_periods=n).mean()

def stochastic_kd(high: pd.Series, low: pd.Series, close: pd.Series,
                  n: int = 9, k_smooth: int = 3, d_period: int = 3) -> Tuple[pd.Series, pd.Series]:
    low_n = low.rolling(n, min_periods=n).min()
    high_n = high.rolling(n, min_periods=n).max()
    denom = (high_n - low_n)
    rsv = (close - low_n) / denom.replace(0, np.nan) * 100.0
    rsv = rsv.fillna(50.0)
    K = rsv.rolling(k_smooth, min_periods=k_smooth).mean()
    D = K.rolling(d_period, min_periods=d_period).mean()
    return K, D

def golden_cross_in_window(K: pd.Series, D: pd.Series, window: int) -> Optional[int]:
    """
    å›å‚³æœ€è¿‘ä¸€æ¬¡é»ƒé‡‘äº¤å‰çš„ç´¢å¼•ä½ç½®ï¼ˆè·ä»Š window ä¹‹å…§ï¼‰ï¼Œå¦å‰‡ Noneã€‚
    é»ƒé‡‘äº¤å‰å®šç¾©ï¼šå‰ä¸€æ—¥ K<=D ä¸”ç•¶æ—¥ K>Dã€‚
    """
    if len(K) < 2 or len(D) < 2:
        return None
    cross_mask = (K.shift(1) <= D.shift(1)) & (K > D)
    cross_idx = np.where(cross_mask.values)[0]
    if cross_idx.size == 0:
        return None
    last_i = len(K) - 1
    # æª¢æŸ¥æ˜¯å¦æœ‰äº¤å‰é»è½åœ¨ [last_i-window+1, last_i]
    lo = max(0, last_i - window + 1)
    recent = cross_idx[cross_idx >= lo]
    if recent.size == 0:
        return None
    return int(recent[-1])  # æœ€è¿‘ä¸€æ¬¡


# ====== åå–®ï¼šä¸Šå¸‚+ä¸Šæ«ƒ â†’ Yahoo ä»£ç¢¼ ======
def build_universe() -> pd.DataFrame:
    """
    éœ€è¦å›å‚³æ¬„ä½ï¼šcode, name, exchange, yahoo
    exchange âˆˆ {"TWSE","TPEX"} â†’ Yahoo å¾Œç¶´åˆ†åˆ¥ç‚º .TW / .TWO
    """
    logger.info("Building universe from TWSE/TPEX ISIN page...")
    df = fetch_twse_listed_equities()
    if "exchange" not in df.columns:
        df["exchange"] = "TWSE"  # èˆŠç‰ˆ fallback

    def to_yahoo(row):
        code4 = str(row["code"]).zfill(4)
        suf = ".TW" if str(row["exchange"]).upper() in ("TWSE", "TSE", "ä¸Šå¸‚") else ".TWO"
        return f"{code4}{suf}"

    df["yahoo"] = df.apply(to_yahoo, axis=1)
    return df[["code", "name", "exchange", "yahoo"]]


# ====== é€ Telegram ======
def send_telegram_message(token: Optional[str], chat_id: Optional[str], text: str) -> None:
    if not token or not chat_id:
        logger.info("Telegram not configured; skip sending.")
        return
    try:
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        resp = requests.post(url, data={"chat_id": chat_id, "text": text})
        if resp.status_code != 200:
            logger.warning("Telegram send failed: %s %s", resp.status_code, resp.text)
        else:
            logger.info("Telegram sent: %d chars", len(text))
    except Exception as e:
        logger.warning("Telegram error: %s", e)


# ====== é€£çºŒå‡ºç¾ï¼ˆstreaksï¼‰è®€å¯« ======
STREAKS_PATH = STATE_DIR / "streaks.json"

def load_streaks() -> Dict[str, Dict]:
    if STREAKS_PATH.exists():
        try:
            return json.loads(STREAKS_PATH.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}

def save_streaks(streaks: Dict[str, Dict]) -> None:
    try:
        STREAKS_PATH.write_text(json.dumps(streaks, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as e:
        logger.warning("Save streaks failed: %s", e)


# ====== å€‹è‚¡è©•ä¼° ======
def evaluate_one(ysym: str, raw_df: pd.DataFrame, params: Dict, market_cap: Optional[float]) -> Optional[Dict]:
    """
    å‚³å›æ»¿è¶³æ¢ä»¶ä¹‹æ‘˜è¦è³‡æ–™ dictï¼Œå¦å‰‡ Noneã€‚
    éœ€è¦æ¬„ä½ï¼šOpen/High/Low/Close/Volume
    """
    if raw_df is None or raw_df.empty:
        return None
    df = raw_df.copy()

    # å¸‚å€¼é–€æª»
    if (market_cap is not None) and (market_cap < params["MARKET_CAP_MIN"]):
        return None

    # éœ€è¦æœ€å°‘çš„æ­·å²é•·åº¦ï¼ˆKDã€MA20ã€é‡èƒ½è¨ˆç®—ï¼‰
    need_len = max(30, params["KD_N"] + params["KD_K_SMOOTH"] + params["KD_D_PERIOD"] + 5, params["VOLUME_LOOKBACK"] + 2)
    if len(df) < need_len:
        return None

    # å‡ç·š
    close = df["Close"]
    df["ma5"] = sma(close, 5)
    df["ma10"] = sma(close, 10)
    df["ma20"] = sma(close, 20)
    if math.isnan(df["ma20"].iloc[-1]) or math.isnan(df["ma10"].iloc[-1]):
        return None

    # KD
    K, D = stochastic_kd(df["High"], df["Low"], close,
                         n=params["KD_N"],
                         k_smooth=params["KD_K_SMOOTH"],
                         d_period=params["KD_D_PERIOD"])
    if math.isnan(K.iloc[-1]) or math.isnan(D.iloc[-1]):
        return None

    # ---- æµ·é¸æ¢ä»¶ ----
    o, c, v = float(df["Open"].iloc[-1]), float(df["Close"].iloc[-1]), float(df["Volume"].iloc[-1])

    # E. æµé€šæ€§ï¼šè¿‘ LIQ_MIN_DAYS æ¯æ—¥é‡ >= LIQ_MIN_SHARES
    liq_days = params["LIQ_MIN_DAYS"]
    liq_min = params["LIQ_MIN_SHARES"]
    if len(df) < liq_days:
        return None
    if (df["Volume"].iloc[-liq_days:] < liq_min).any():
        return None

    # D. æ”¾é‡ï¼šä»Šæ—¥é‡ / (éå»20æ—¥å‡é‡ï¼Œä¸å«ä»Šæ—¥) >= å€æ•¸
    look = params["VOLUME_LOOKBACK"]
    past20 = df["Volume"].iloc[-(look+1):-1]  # ä¸å«ä»Šæ—¥
    if len(past20) < look:
        return None
    v20 = float(past20.mean())
    if v20 <= 0:
        return None
    vol_ratio = v / v20
    if vol_ratio < params["VOLUME_MULTIPLIER"]:
        return None

    # D2. é»‘K é™åˆ¶ï¼šè‹¥ c<oï¼Œå‰‡ c >= o * 0.95
    if params["ENABLE_RULE_BLACK_CANDLE_LIMIT"]:
        if c < o and c < o * params["BLACK_CANDLE_MAX_DROP"]:
            return None

    # B1. MA5 > MA20
    if params["ENABLE_RULE_MA5_GT_MA20"]:
        if not (df["ma5"].iloc[-1] > df["ma20"].iloc[-1]):
            return None

    # B2. é–‹ç›¤ or æ”¶ç›¤ >= MA20
    if params["ENABLE_RULE_OC_ABOVE_MA20"]:
        if not (o >= df["ma20"].iloc[-1] or c >= df["ma20"].iloc[-1]):
            return None

    # B3. è¿‘5æ—¥ æ”¶ç›¤<MA10 çš„å¤©æ•¸ <= é–¾å€¼
    if params["ENABLE_RULE_LAST5_MA10_THRESHOLD"]:
        last5 = df.iloc[-5:]
        cnt_below = int((last5["Close"] < last5["ma10"]).sum())
        if cnt_below > params["MAX_DAYS_BELOW_MA10_IN_5"]:
            return None

    # C. è¿‘3æ—¥ KD é»ƒé‡‘äº¤å‰ï¼Œä¸”ç•¶ä¸‹ K>D
    if not (K.iloc[-1] > D.iloc[-1]):
        return None
    cross_idx = golden_cross_in_window(K, D, params["KD_CROSS_WINDOW"])
    if cross_idx is None:
        return None

    # ---- é€šéï¼šè¨ˆç®—è¼¸å‡ºå› å­ ----
    kd_spread = float(K.iloc[-1] - D.iloc[-1])
    price_ma20_pct = float((c - df["ma20"].iloc[-1]) / df["ma20"].iloc[-1])

    return dict(
        date=pd.to_datetime(df.index[-1]).date().isoformat(),
        open=o,
        close=c,
        volume=v,
        ma5=float(df["ma5"].iloc[-1]),
        ma10=float(df["ma10"].iloc[-1]),
        ma20=float(df["ma20"].iloc[-1]),
        K=float(K.iloc[-1]),
        D=float(D.iloc[-1]),
        kd_spread=kd_spread,
        kd_cross_day=pd.to_datetime(df.index[cross_idx]).date().isoformat(),
        volume_ratio=float(vol_ratio),
        price_ma20_pct=price_ma20_pct,
    )


# ====== ä¸»è¦æµç¨‹ ======
def run_once():
    params = get_env_params()

    # 1) å»ºå®‡å®™
    uni = build_universe()
    logger.info("Universe size: %d", len(uni))
    tickers: List[str] = uni["yahoo"].tolist()
    code_map = dict(zip(uni["yahoo"], uni["code"]))
    name_map = dict(zip(uni["yahoo"], uni["name"]))
    exch_map = dict(zip(uni["yahoo"], uni["exchange"]))

    # 2) ä¸‹è¼‰åƒ¹é‡
    logger.info("Downloading OHLCV from Yahoo in batches...")
    data_map: Dict[str, pd.DataFrame] = download_ohlcv_batches(
        tickers, period="6mo", interval="1d",
        batch_size=params["BATCH_SIZE"], retries=2, sleep_sec=1.0
    )

    # æª¢æŸ¥æ˜¯å¦ç‚ºã€Œéäº¤æ˜“æ—¥ã€
    # å–å¾—æ‰€æœ‰æœ‰è³‡æ–™æ¨™çš„çš„æœ€æ–°æ—¥æœŸï¼Œèˆ‡å°åŒ—ç•¶æ—¥æ¯”è¼ƒï¼ˆè‹¥å°æ–¼ä»Šæ—¥ â†’ è¦–ç‚ºéäº¤æ˜“æ—¥ï¼‰
    dates = []
    ref_prev = None
    for df in data_map.values():
        if df is not None and not df.empty:
            dates.append(pd.to_datetime(df.index[-1]).date())
            if ref_prev is None and len(df) >= 2:
                ref_prev = pd.to_datetime(df.index[-2]).date()
    if not dates:
        dates = []
    latest_trade_date = max(dates) if dates else None
    today_tpe = datetime.now(ZoneInfo("Asia/Taipei")).date()

    if (latest_trade_date is None) or (latest_trade_date < today_tpe):
        # å»ºç«‹ç©º CSV ä»¥ä¾¿ workflow ä¸Šå‚³ artifact
        out_empty = OUTPUT_DIR / f"picks_{today_tpe.strftime('%Y%m%d')}.csv"
        pd.DataFrame(columns=[
            "date","code","name","exchange","yahoo","close","K","D","volume_ratio",
            "kd_spread","price_ma20_pct","score","continuation_days"
        ]).to_csv(out_empty, index=False, encoding="utf-8-sig")
        # å‹å–„è¨Šæ¯
        send_telegram_message(params["TELEGRAM_BOT_TOKEN"], params["TELEGRAM_CHAT_ID"],
                              "ä»Šæ—¥ç‚ºéäº¤æ˜“æ—¥ï¼Œè«‹é–‹å¿ƒéå¥½æ¯ä¸€å¤©")
        logger.info("No today bars -> Non-trading day. Wrote empty CSV: %s", out_empty)
        return

    # 3) å¸‚å€¼
    logger.info("Fetching market caps from Yahoo...")
    mc_map = get_market_caps(tickers, retries=1, sleep=0.05)

    # 4) è©•ä¼°å…¨éƒ¨
    rows = []
    for ysym, df in data_map.items():
        try:
            sig = evaluate_one(ysym, df, params, market_cap=mc_map.get(ysym))
            if sig:
                rows.append({
                    "date": sig["date"],
                    "code": code_map.get(ysym, ""),
                    "name": name_map.get(ysym, ""),
                    "exchange": exch_map.get(ysym, ""),
                    "yahoo": ysym,
                    "open": sig["open"],
                    "close": sig["close"],
                    "volume": sig["volume"],
                    "ma5": sig["ma5"],
                    "ma10": sig["ma10"],
                    "ma20": sig["ma20"],
                    "K": sig["K"],
                    "D": sig["D"],
                    "kd_spread": sig["kd_spread"],
                    "kd_cross_day": sig["kd_cross_day"],
                    "volume_ratio": sig["volume_ratio"],
                    "price_ma20_pct": sig["price_ma20_pct"],
                    "market_cap": mc_map.get(ysym)
                })
        except Exception as e:
            logger.warning("Signal evaluation failed for %s: %s", ysym, e)

    # ç„¡æ¨™çš„ â†’ ä»è¼¸å‡ºç©ºæª”
    today_str = latest_trade_date.strftime("%Y%m%d")
    base_cols = ["date","code","name","exchange","yahoo","close","K","D","volume_ratio",
                 "kd_spread","price_ma20_pct","rank_kd","rank_vol","a","b","c","score","continuation_days"]
    if not rows:
        out_path = OUTPUT_DIR / f"picks_{today_str}.csv"
        pd.DataFrame(columns=base_cols).to_csv(out_path, index=False, encoding="utf-8-sig")
        send_telegram_message(params["TELEGRAM_BOT_TOKEN"], params["TELEGRAM_CHAT_ID"], "ä»Šæ—¥ç„¡ç¬¦åˆæ¢ä»¶ä¹‹å€‹è‚¡ã€‚")
        logger.info("Saved empty results to %s", out_path)
        return

    df_all = pd.DataFrame(rows)

    # 5) ä¸‰å› å­æ’åèˆ‡åˆ†æ•¸
    # ä¾ kd_spreadã€volume_ratio ç”±é«˜åˆ°ä½æ’åºå–å¾—åæ¬¡ï¼ˆ1=æœ€å¥½ï¼‰
    df_all["rank_kd"] = df_all["kd_spread"].rank(method="min", ascending=False).astype(int)
    df_all["rank_vol"] = df_all["volume_ratio"].rank(method="min", ascending=False).astype(int)

    # a=(2-0.02*n_k)ï¼Œb=(2-0.02*n_v)ï¼›é¿å…ç‚ºè² ï¼Œåšä¸‹é™ 0
    df_all["a"] = (2.0 - 0.02 * df_all["rank_kd"]).clip(lower=0.0)
    df_all["b"] = (2.0 - 0.02 * df_all["rank_vol"]).clip(lower=0.0)
    df_all["c"] = df_all["price_ma20_pct"]
    df_all["score"] = df_all["a"] * df_all["b"] * df_all["c"]

    # 6) å–å‰ TOP_N
    df_all = df_all.sort_values("score", ascending=False).reset_index(drop=True)
    df_top = df_all.head(params["TOP_N"]).copy()

    # 7) é€£çºŒå‡ºç¾ï¼ˆä»¥æ˜¨æ—¥äº¤æ˜“æ—¥ç‚ºæº–ï¼‰
    prev_trade_date = ref_prev or (latest_trade_date)  # è‹¥ç¼ºï¼Œå°±ç„¡æ³•åˆ¤æ–·åš´è¬¹é€£çºŒï¼Œè¦–ç‚ºé¦–æ¬¡
    key_field = params.get("CONTINUATION_KEY", "yahoo")
    if key_field not in df_top.columns:
        key_field = "yahoo"

    streaks = load_streaks()  # { key: {"last_date":"YYYY-MM-DD","streak":int} }
    updated = {}

    cont_days = []
    for _, r in df_top.iterrows():
        key = str(r[key_field])
        prev = streaks.get(key)
        if prev and prev.get("last_date") == str(prev_trade_date):
            days = int(prev.get("streak", 1)) + 1
        else:
            days = 1
        cont_days.append(days)
        updated[key] = {"last_date": str(latest_trade_date), "streak": days}
    df_top["continuation_days"] = cont_days

    # æ¸…ç†èˆŠ streaksï¼šåƒ…ä¿ç•™ä»Šæ—¥æ¦œå–®ä¸­çš„ keyï¼ˆé¿å…ç„¡é™è†¨è„¹ï¼‰
    save_streaks(updated)

    # 8) ä¾ã€Œæ˜¯å¦é€£çºŒ >=2ã€åˆ†å…©å¼µè¡¨
    df_cont = df_top[df_top["continuation_days"] >= 2].copy()
    df_fresh = df_top[df_top["continuation_days"] == 1].copy()

    # 9) è¼¸å‡º CSV
    out_all = OUTPUT_DIR / f"picks_{today_str}.csv"
    out_cont = OUTPUT_DIR / f"picks_{today_str}_top_continuous.csv"
    out_fresh = OUTPUT_DIR / f"picks_{today_str}_top_fresh.csv"
    # çµ±ä¸€æ¬„ä½é †åº
    order_cols = ["date","code","name","exchange","yahoo","close","K","D","volume_ratio",
                  "kd_spread","price_ma20_pct","rank_kd","rank_vol","a","b","c","score","continuation_days"]
    df_top[order_cols].to_csv(out_all, index=False, encoding="utf-8-sig")
    df_cont[order_cols].to_csv(out_cont, index=False, encoding="utf-8-sig")
    df_fresh[order_cols].to_csv(out_fresh, index=False, encoding="utf-8-sig")
    logger.info("Saved results: all=%s (count=%d), cont=%s (%d), fresh=%s (%d)",
                out_all, len(df_top), out_cont, len(df_cont), out_fresh, len(df_fresh))

    # 10) Telegram æ‘˜è¦ï¼ˆåªé¡¯ç¤ºï¼šæ”¶ç›¤ã€KDã€æ”¾é‡å€æ•¸ï¼›é€£çºŒæ¸…å–®åŠ ä¸Šã€Œé€£Nã€ï¼‰
    def fmt_row(r) -> str:
        return f"{r['code']} {r['name']} | æ”¶ {r['close']:.2f} | KD {r['K']:.1f}/{r['D']:.1f} | é‡ {r['volume_ratio']:.2f}x"

    lines: List[str] = []
    lines.append(f"ğŸ“ˆ {latest_trade_date} KDé¸è‚¡ï¼ˆå‰{params['TOP_N']}ï¼‰")

    if len(df_cont) > 0:
        lines.append("â€” é€£çºŒå‡ºç¾ï¼ˆâ‰¥2å¤©ï¼‰ â€”")
        for _, r in df_cont.iterrows():
            lines.append(fmt_row(r) + f" | é€£{int(r['continuation_days'])}")
    else:
        lines.append("â€” é€£çºŒå‡ºç¾ï¼ˆâ‰¥2å¤©ï¼‰ â€” ç„¡")

    if len(df_fresh) > 0:
        lines.append("â€” éé€£çºŒ â€”")
        for _, r in df_fresh.iterrows():
            lines.append(fmt_row(r))
    else:
        lines.append("â€” éé€£çºŒ â€” ç„¡")

    msg = "\n".join(lines)
    send_telegram_message(params["TELEGRAM_BOT_TOKEN"], params["TELEGRAM_CHAT_ID"], msg)


if __name__ == "__main__":
    try:
        run_once()
    except Exception as e:
        logger.error("Fatal error: %s\n%s", e, traceback.format_exc())
        # ç›¡é‡å›å ±éŒ¯èª¤åˆ° Telegramï¼Œæ–¹ä¾¿é ç«¯çœ‹
        try:
            p = get_env_params()
            send_telegram_message(p.get("TELEGRAM_BOT_TOKEN"), p.get("TELEGRAM_CHAT_ID"),
                                  f"âŒ Screener å¤±æ•—ï¼š{e}")
        except Exception:
            pass
        sys.exit(1)
